{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ccc8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad494c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169c5911c05044448f09ad23d4c478fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039469ef8c1d42adbe31da89fe936f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/108M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c3db4e796741bf8f143509be75bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/362k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a90f32312849f4b5c617d1f30a2628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/342k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958eee2305564c688829e24df10884d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/610320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18bf23209cdc4ee8909ab8f96da2893e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cc3409e3c64a17b98784767e5347ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 1. Load dataset (WMT16 English-Romanian)\n",
    "dataset = load_dataset(\"wmt16\", \"ro-en\", split=\"train[:200]\")  # Small subset for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ca69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060eda981a5e473c8e006f6a7e488f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b566ce0cdcc44e8867a0f2184d41b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/789k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f82a43326b412592e38a153f746db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/817k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca3e6358e294907a79096628880df8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7560db08b77c4c6f911d76a73caea8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6427de596244fd0a604c9a0c461257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26bcf3907554cdea605de9b06887215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46feee1f4bb84828bc46e36f5dfbaaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 2. Load tokenizer and model for English to Romanian\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-ro\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d947b347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f02e03df7d42fc859fe392dd94b4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Tokenization function\n",
    "def tokenize(example):\n",
    "    inputs = tokenizer(example[\"translation\"][\"en\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        targets = tokenizer(example[\"translation\"][\"ro\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b2bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. PyTorch-compatible dataset class\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.input_ids = hf_dataset[\"input_ids\"]\n",
    "        self.attention_mask = hf_dataset[\"attention_mask\"]\n",
    "        self.labels = hf_dataset[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.input_ids[idx]),\n",
    "            \"attention_mask\": torch.tensor(self.attention_mask[idx]),\n",
    "            \"labels\": torch.tensor(self.labels[idx]),\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(tokenized_dataset)\n",
    "dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd8e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch complete | Loss: 0.0739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\"âœ… Epoch complete | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fc3484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to ./finetuned-en-ro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[59542]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Save model\n",
    "model.save_pretrained(\"./finetuned-en-ro\")\n",
    "tokenizer.save_pretrained(\"./finetuned-en-ro\")\n",
    "print(\"âœ… Model saved to ./finetuned-en-ro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cedf676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BLEU score on 50 examples: 0.5729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. BLEU evaluation\n",
    "bleu = load(\"bleu\")\n",
    "model.eval()\n",
    "predictions, references = [], []\n",
    "sample_dataset = tokenized_dataset.select(range(50))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in sample_dataset:\n",
    "        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "        output_ids = model.generate(input_ids, max_length=128)[0]\n",
    "        pred = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        ref = tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
    "        predictions.append(pred.strip())\n",
    "        references.append([ref.strip()])\n",
    "\n",
    "score = bleu.compute(predictions=predictions, references=references)\n",
    "print(f\"âœ… BLEU score on 50 examples: {score['bleu']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
