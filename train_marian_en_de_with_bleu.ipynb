{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cb5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from evaluate import load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b008cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load dataset\n",
    "#dataset = load_dataset(\"wmt14\", \"de-en\", split=\"train[:1%]\")  # small subset for dev\n",
    "dataset = load_dataset(\"wmt14\", \"de-en\", split=\"train[:200]\")  # just 200 samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664cac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Load tokenizer and model\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9ed9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Tokenize\n",
    "def tokenize(example):\n",
    "    inputs = tokenizer(example[\"translation\"][\"en\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        targets = tokenizer(example[\"translation\"][\"de\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "796a90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Torch-compatible dataset\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.input_ids = hf_dataset[\"input_ids\"]\n",
    "        self.attention_mask = hf_dataset[\"attention_mask\"]\n",
    "        self.labels = hf_dataset[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(self.input_ids[idx]),\n",
    "            \"attention_mask\": torch.tensor(self.attention_mask[idx]),\n",
    "            \"labels\": torch.tensor(self.labels[idx]),\n",
    "        }\n",
    "\n",
    "train_dataset = TranslationDataset(tokenized_dataset)\n",
    "dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2189bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch complete | Loss: 0.3315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(f\" Epoch complete | Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36b13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved to ./simple-finetuned-en-de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:3353: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. Save model\n",
    "model.save_pretrained(\"./simple-finetuned-en-de\")\n",
    "tokenizer.save_pretrained(\"./simple-finetuned-en-de\")\n",
    "print(\" Model saved to ./simple-finetuned-en-de\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3faf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BLEU score on 100 examples: 0.3236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Evaluate BLEU on a few examples\n",
    "bleu = load(\"bleu\")\n",
    "model.eval()\n",
    "predictions, references = [], []\n",
    "sample_dataset = tokenized_dataset.select(range(100))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in sample_dataset:\n",
    "        input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "        output_ids = model.generate(input_ids, max_length=128)[0]\n",
    "        pred = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "        ref = tokenizer.decode(example[\"labels\"], skip_special_tokens=True)\n",
    "        predictions.append(pred.strip())\n",
    "        references.append([ref.strip()])\n",
    "\n",
    "score = bleu.compute(predictions=predictions, references=references)\n",
    "print(f\" BLEU score on 100 examples: {score['bleu']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
